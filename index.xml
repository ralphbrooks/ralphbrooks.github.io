<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI Best Practices</title>
    <link>https://ralphabrooks.com/</link>
    <description>Recent content on AI Best Practices</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 27 Jul 2019 11:18:53 -0400</lastBuildDate>
    
	<atom:link href="https://ralphabrooks.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Categorical Cross Entropy</title>
      <link>https://ralphabrooks.com/deep_learning/dictionary/categoricalcrossentropy/</link>
      <pubDate>Sat, 27 Jul 2019 11:18:53 -0400</pubDate>
      
      <guid>https://ralphabrooks.com/deep_learning/dictionary/categoricalcrossentropy/</guid>
      <description>These are some additional notes that I am taking on the incredible book by David Foster on Generative Deep LearningThe calculation for this is:
$$\Huge - \overset{n}{\underset{i = 1}{\Sigma}} y_i\space log(p_i)$$
This simply shows the log of the prediction times the ground truth. Then you sum all of this up for each data point.</description>
    </item>
    
    <item>
      <title>Mean Squared Error</title>
      <link>https://ralphabrooks.com/deep_learning/dictionary/mse/</link>
      <pubDate>Sat, 27 Jul 2019 11:18:53 -0400</pubDate>
      
      <guid>https://ralphabrooks.com/deep_learning/dictionary/mse/</guid>
      <description>These are some additional notes that I am taking on the incredible book by David Foster on Generative Deep LearningMSE stands for Mean Squared Error. The calculation for this is:
$$\Huge MSE = \frac{1}{n}\overset{n}{\underset{i = 1}{\Sigma}} (y_i - p_i)^2$$
This simply shows the difference between the ground truth ($y_i$) and what is predicted ($p_i$). This is typically used when trying to solve regression problems.</description>
    </item>
    
    <item>
      <title>Deep Learning Dictionary</title>
      <link>https://ralphabrooks.com/deep_learning/general/deep_learning_dictionary/</link>
      <pubDate>Sun, 14 Jul 2019 12:25:53 -0400</pubDate>
      
      <guid>https://ralphabrooks.com/deep_learning/general/deep_learning_dictionary/</guid>
      <description>Additive Smoothing : When calculating the maximum likelihood estimate $\theta_j$, you want to make sure that even unlikely possibilities could be generated in the additive model. Discussed in Generative Deep Learning - July 2019 - David Foster - Chapter 1
Activations : These are tne nonlinearities that rae introduced within Dense layers.
 Sigmoid - This is used for multiclass classification (when an item can belong to more than one class ).</description>
    </item>
    
    <item>
      <title>General Notes</title>
      <link>https://ralphabrooks.com/deep_learning/general/general_notes/</link>
      <pubDate>Sun, 14 Jul 2019 12:25:53 -0400</pubDate>
      
      <guid>https://ralphabrooks.com/deep_learning/general/general_notes/</guid>
      <description>The following are a collection of general random notes that I have collected. They are not organized, but may be informative.
TF has a addons repo which contains things that are not in the core Tensorflow repo.
 Tensorflow has a models repo which shows best practices.
 Use tf.summary.histogram in order to record relevant tensors. This can be later examined within TensorBoard.
 In tf 1.13, you can use tf.</description>
    </item>
    
    <item>
      <title>Approaches to Class Imbalance</title>
      <link>https://ralphabrooks.com/data_science/general/approaches_to_class_imbalance/</link>
      <pubDate>Tue, 04 Jun 2019 12:25:53 -0400</pubDate>
      
      <guid>https://ralphabrooks.com/data_science/general/approaches_to_class_imbalance/</guid>
      <description>In situations where there is class imbalance, it is helpful to look not only at accuracy, but to look at
 Precision Recall F1 scores  Deep learning approches to get better balancing include:
 Assigning weights when doing the fit Using focal_loss for the loss method  </description>
    </item>
    
    <item>
      <title>About Ralph Brooks</title>
      <link>https://ralphabrooks.com/about/ralph_brooks/</link>
      <pubDate>Sun, 02 Jun 2019 11:53:49 -0700</pubDate>
      
      <guid>https://ralphabrooks.com/about/ralph_brooks/</guid>
      <description>About Ralph Brooks I am a data scientist and machine learning engineer with over a decade of experience in applying data science, deep learning, and software engineering in order to create value for Fortune 500 companies.
I am currently living in Frisco, TX.
 Twitter: @ralphbrooks LinkedIn: https://www.linkedin.com/in/ralphbrooks/  Current Projects Currently, I am working on data science as well as building out the infrastructure needed to do distributed deep learning.</description>
    </item>
    
    <item>
      <title>Deep Learning Checklist</title>
      <link>https://ralphabrooks.com/deep_learning/keras/deep_learning_checklist/</link>
      <pubDate>Sun, 02 Jun 2019 12:25:53 -0400</pubDate>
      
      <guid>https://ralphabrooks.com/deep_learning/keras/deep_learning_checklist/</guid>
      <description> Define the problem Identify a way to reliably measure success against a goal Prepare a validation process that you will use to evaluate models Vectorize the data Develop a model that beats a trivial common sense baseline Refine model architecture Get your model to overfit  After overfitting use the following to refine model architecture
 Add regularization (dropout) to the model Downsize the model to use lower capacity  </description>
    </item>
    
    <item>
      <title>Freezing a layer in Keras</title>
      <link>https://ralphabrooks.com/deep_learning/keras/freezing_layers/</link>
      <pubDate>Tue, 28 May 2019 12:25:53 -0400</pubDate>
      
      <guid>https://ralphabrooks.com/deep_learning/keras/freezing_layers/</guid>
      <description>To freeze a layer in Keras, use:
model.layers[0].trainable = False Notes:
 Typically, the freezing of layers will be done so that weights which are learned in prior stages are not forgotten in later layers of the model. For example, if you have BERT as one part of a Keras TensorFlow model, that layer might need to be frozen so that large changes in gradient that occur during fine tuning do not distrupt the weights that have been learned in BERT.</description>
    </item>
    
    <item>
      <title>How to Set Environment Variables From A Linux Script</title>
      <link>https://ralphabrooks.com/linux/environment/setting_environment_variables_from_script/</link>
      <pubDate>Mon, 27 May 2019 12:25:53 -0400</pubDate>
      
      <guid>https://ralphabrooks.com/linux/environment/setting_environment_variables_from_script/</guid>
      <description>If you utilize the cloud, odds are that there has been a time where you spun up a machine and needed to set the environment variables from a linux script.
The process to do this is:
1) Create a file that contains environment variables that you want to export.
environ.sh
export APIKEY=&amp;#34;Sample API key&amp;#34; 2) Change the permissions of the environment file:
chmod +x environ.sh 3) Execute the script with a dot space prefix.</description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>https://ralphabrooks.com/articles/intro/</link>
      <pubDate>Mon, 27 May 2019 12:25:53 -0400</pubDate>
      
      <guid>https://ralphabrooks.com/articles/intro/</guid>
      <description>I am a data scientist and machine learning engineer in Frisco, TX where I am working on items at the interaction of deep learning, natural language processing, and Bayesian statistics.</description>
    </item>
    
    <item>
      <title>Using a confusion matrix within Keras</title>
      <link>https://ralphabrooks.com/deep_learning/keras/using_confusion_matrix_with_keras/</link>
      <pubDate>Mon, 27 May 2019 12:25:53 -0400</pubDate>
      
      <guid>https://ralphabrooks.com/deep_learning/keras/using_confusion_matrix_with_keras/</guid>
      <description>Assuming that y_label are the actual gold standard labels that you want to evaluate, you can use sklearn&amp;rsquo;s confusion matrix function in order to evaluate a keras model.
Code would look like the following
import numpy as np from sklearn.metrics import confusion_matrix model = &amp;lt;use your favorite keras model here&amp;gt; y_pred = model.predict(test_data, test_labels) y_pred_max = np.apply_along_axis(lambda x : np.argmax(x) +1, axis =1, arr=y_pred) cm = confusion_matrix(test_label, y_pred_max)</description>
    </item>
    
  </channel>
</rss>